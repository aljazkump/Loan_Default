{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505b5d4d-3e8d-4d25-9a90-aa14f4bc498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21be47d1-7f62-4ddd-aa11-d49dfaa22cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:09<00:00, 1075969.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 149062.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1648877/1648877 [00:01<00:00, 1632278.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_set = MNIST('', train=True, download=True, \n",
    "                  transform=transform.Compose([transform.ToTensor(), transform.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "test_set = MNIST('', train=False, download=True, \n",
    "                 transform=transform.Compose([transform.ToTensor(), transform.Normalize((0.1307,), (0.3081,))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a454d5d-6740-45d8-ba06-de1f4f6c2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "loader = {\n",
    "    \"train\" : DataLoader(train_set, batch_size = batch_size, shuffle = True),\n",
    "    \"test\" : DataLoader(test_set, batch_size = batch_size, shuffle = True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0be41-b7c9-40e3-ad63-61629b461efd",
   "metadata": {},
   "source": [
    "### FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc31f3f-b0a0-4706-9eba-b365eb91d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Definiramo objekt, ki bo sliko spremenil v vektor\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Definiramo sloje nevronske mreže\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Vhodno sliko pretvorimo v vektor\n",
    "        x = self.flatten(x)\n",
    "        # Vektor pošljemo čez vse sloje in aktivacijske vrednosti\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        # Izhod iz nevronske mreže pretvorimo v \"verjetnosti\" za vsako ciljno vrednost\n",
    "        return self.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107bd5b7-3e9c-4731-a669-7b329d735943",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beb58c24-4d2d-47f8-bda2-06e0072130f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):  \n",
    "    # Zagotovimo, da bo model v načinu treniranja, kjer se računajo gradienti in so aktivni vsi sloji\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        with tqdm(total = len(loader[\"train\"]) * batch_size, desc = f'Training - Epoch: {epoch + 1}/{epochs}', unit = 'chunks') as prog_bar:\n",
    "            # Gremo čez vse podatke v skupinah po batch_size z trainloaderjem, v našem primeru je to 32\n",
    "            for i, data in enumerate(loader[\"train\"], 0):\n",
    "                # Podatke razpakiramo v vhode in izhode \n",
    "                inputs, labels = data\n",
    "                # Resetiramo gradiente v podatkih\n",
    "                optimizer.zero_grad()\n",
    "                # Vhodne podatke spustimo čez model, ta nam vrne matriko, v kateri se vsaka vrstica sešteje v 1 (zaradi Softmax sloja)\n",
    "                outputs = model(inputs)\n",
    "                # Izračunamo izgubo\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Naredimo vzvratno razširanje napake (backpropagation)\n",
    "                loss.backward()\n",
    "                # Naredimo en korak optimizacije\n",
    "                optimizer.step()\n",
    "                # Dodamo izgubo k naši vsoti izgube.\n",
    "                running_loss += loss.detach().item()\n",
    "                prog_bar.set_postfix(**{'loss': (running_loss) / (i+1)})\n",
    "                prog_bar.update(batch_size)\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07a9c836-d07b-4985-9b8c-45209a468fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss, correct, counter = 0, 0, 0\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        with tqdm(total = len(loader[\"test\"]) * batch_size, desc = f'Testing', unit = 'chunks') as prog_bar:\n",
    "            for i, data in enumerate(loader[\"test\"], 0):\n",
    "                inputs, labels = data\n",
    "                output = model(inputs)\n",
    "                test_loss += criterion(output, labels).detach().item()\n",
    "                # Izberemo indekse mesta z najvišjo vrednostjo (\"verjetnostjo\")\n",
    "                pred = output.data.max(1, keepdim = True)[1]\n",
    "                # Prištejemo število primerov, kjer smo zadeli pravilen rezultat\n",
    "                correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "                prog_bar.update(batch_size)\n",
    "                counter += 1\n",
    "    print(f'Test set: Avg. loss: {test_loss/counter}, Correct predictions: {correct}/{len(loader[\"test\"].dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03251d73-c879-488a-9dda-28d64c47efc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 1/5: 100%|████████████████████████████████████| 60000/60000 [00:40<00:00, 1492.02chunks/s, loss=1.48]\n",
      "Training - Epoch: 2/5: 100%|████████████████████████████████████| 60000/60000 [00:39<00:00, 1502.24chunks/s, loss=1.48]\n",
      "Training - Epoch: 3/5: 100%|████████████████████████████████████| 60000/60000 [00:41<00:00, 1455.34chunks/s, loss=1.48]\n",
      "Training - Epoch: 4/5: 100%|████████████████████████████████████| 60000/60000 [00:40<00:00, 1487.65chunks/s, loss=1.48]\n",
      "Training - Epoch: 5/5: 100%|████████████████████████████████████| 60000/60000 [00:40<00:00, 1475.20chunks/s, loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████████████████████████████████████████████████████████| 10016/10016 [00:04<00:00, 2019.61chunks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 1.4944515479639315, Correct predictions: 9669/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(5)\n",
    "print(\"\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2497ac7-c828-4bdb-91d9-e96f3a4293c4",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec8b2c80-9dca-4449-803b-ff45076d1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Ker bomo delali na slikah (2d matrikah) slike ne rabimo pretvoriti v vektor\n",
    "        self.convolution = nn.Sequential(\n",
    "            # Začnemo s konvolucijskim slojem. Ta bo na vhod dobil 1 kanal (ker je slika črno bela)\n",
    "            # na izhod pa vrnila 16 kanalov (sami definiramo koliko). Velikost konvolucijskega filtra\n",
    "            # nadzorujemo z parametrom kernel_size, v našem primeru bodo filtri velikosti 3x3\n",
    "            nn.Conv2d(1, 16, kernel_size=3),\n",
    "            # Dobljene kanale pošljemo čez relu funkcijo\n",
    "            nn.ReLU(),\n",
    "            # Sliko pomanjšamo z maxpool slojem. Jedro tega bo velikosti 2 v našem primeru\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        # Na koncu bomo ciljno vrednost napovedali s polno povezanim slojem. Ta na vhod prejme kanale\n",
    "        # iz prejšnjega sloja pretvorjene v vektor. Teh je 16, vsak velikosti 13x13. \n",
    "        self.fc = nn.Linear(16*13*13, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Podatke pošljemo čez konvolucijo\n",
    "        x = self.convolution(x)\n",
    "        # Kanale pretvorimo v vektorje z ukazom reshape\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        # Napovemo ciljno vrednost s polno povezanim slojem\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdf58968-eda5-4de2-a151-89d868dd3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c20688b9-40f4-49bb-b799-3e4cd02369c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 1/5: 100%|███████████████████████████████████| 60000/60000 [00:54<00:00, 1103.58chunks/s, loss=0.193]\n",
      "Training - Epoch: 2/5: 100%|██████████████████████████████████| 60000/60000 [00:55<00:00, 1089.43chunks/s, loss=0.0792]\n",
      "Training - Epoch: 3/5: 100%|██████████████████████████████████| 60000/60000 [00:52<00:00, 1139.38chunks/s, loss=0.0612]\n",
      "Training - Epoch: 4/5: 100%|██████████████████████████████████| 60000/60000 [00:52<00:00, 1138.89chunks/s, loss=0.0497]\n",
      "Training - Epoch: 5/5: 100%|██████████████████████████████████| 60000/60000 [00:52<00:00, 1143.48chunks/s, loss=0.0419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████████████████████████████████████████████████████████| 10016/10016 [00:06<00:00, 1605.39chunks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 0.060103129838948874, Correct predictions: 9808/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(5)\n",
    "print(\"\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf2992-ad0b-4c04-bb08-5ae06b033a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c244a-174b-4e22-9dc5-8531ac0f7b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db537b38-6b15-4a77-8318-eacbcc6dec9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
